{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from sentence-transformers) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: numpy in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from sentence-transformers) (0.24.6)\n",
      "Requirement already satisfied: Pillow in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeong-uihyeon/chatbot/.venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Batches: 100%|██████████| 138/138 [00:19<00:00,  6.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# 이전 코드 파트 (how to make vector DB 보면 주석이 더 자세히 달려있음)\n",
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "directory_path = r\"/Users/jeong-uihyeon/chatbot/file/Sample/02.라벨링데이터\"  #원하는 경로 (일단 한정해 두었음)\n",
    "\n",
    "def load_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file) # 전체 내용\n",
    "    except FileNotFoundError:\n",
    "        data = \"파일을 찾을 수 없습니다.\"\n",
    "    except json.JSONDecodeError:\n",
    "        data = \"유효하지 않은 JSON 형식입니다.\"\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_json_files(directory):\n",
    "    question = []\n",
    "    answer = []\n",
    "    \n",
    "    # 디렉토리와 하위 디렉토리를 탐색\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # 파일 확장자가 .json인지 확인\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                # JSON 파일 읽기\n",
    "                data = load_json(file_path)\n",
    "                # json파일에서 question / answer 쌍으로 추출\n",
    "                question.append(data['question'][\"comment\"])\n",
    "                answer.append(data['answer'][\"comment\"])\n",
    "                \n",
    "    return question, answer\n",
    "\n",
    "\n",
    "def embed_text(texts, model):\n",
    "    return model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "\n",
    "# 질문 답변 쌍으로 저장\n",
    "questions, answers = read_json_files(directory_path)\n",
    "\n",
    "# Sentence-BERT 모델 로드\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# 결합된 텍스트를 벡터로 변환\n",
    "combined_vectors = embed_text(questions, model)\n",
    "\n",
    "# 질문 전부를 임베딩하기\n",
    "qustion_vectors = model.encode(questions)\n",
    "\n",
    "# 질문 벡터의 차원 확인\n",
    "vector_dimension = len(qustion_vectors[0])\n",
    "\n",
    "#Faiss index 생성\n",
    "index = faiss.IndexFlatL2(vector_dimension)\n",
    "\n",
    "# 인덱스에 벡터 추가\n",
    "index.add(np.array(qustion_vectors).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: 그러니까 내가 아까 얘기한 부산지검의 명예를 회복하기 위해서 해야 된다는 얘기이고 그 이전의 지검 검사장도 이 지역사회에서 유착되었다는 설도 여기에서는 널리 유포되어 있었습니다. 그런데다가 최근에 두 지검 검사장이 이 사건의 변호인으로 선임되고 하니까 점점 부산지검은 다대ㆍ만덕사건에 관한 한 처음부터 수사를 못 하게 되어 있는 사건이다, 내가 아까 말한 대로 국정감사 때마다 요구하고 추궁하고 또 감사원 감사가 착수되고 하니까 할 수 없이 등 떠밀려서 마지못해서 하는 것 아니냐 하는 것입니다.  수사진은 왜 교체했습니까?\n",
      "answer: 인사가 된 것이 금년 2월인데 그때는 이영복이가 이미 도주했고 나머지 사람들에 대해서는 1월 중에 다 기소된 뒤였습니다. 그렇기 때문에 정기인사에 따라서 부장검사가 서울로 갈 차례이고 또 수사검사는 부부장으로 승진을 하게 되어 있었습니다.  저희들 관행에 따르면 부부장검사로 승진을 하면 다른 청에 가게 되어 있습니다. 그렇게 해서 가기는 했습니다마는 후임 부장이나 후임 검사들의 수사열의는 또 수사에 대한 파악도는 전임자들에 결코 못지않다는 것을 말씀드립니다.\n",
      "distance: 1.8244607213890873e-11\n"
     ]
    }
   ],
   "source": [
    "def search_qa(query, k=1):\n",
    "    # 질문(query)를 vector로 변환\n",
    "    query_vector = model.encode([query])\n",
    "\n",
    "    # distances는 query와 가장 가까운 값의 유사도\n",
    "    # indices는 query와 가장 가까운 값의 인덱스 값\n",
    "    distances, indices = index.search(np.array(query_vector).astype('float32'), k)\n",
    "    return [(questions[i], answers[i], distances[0][j]) for j, i in enumerate(indices[0])] # k값이 복수일 경우 값들을 불러줌\n",
    "\n",
    "results = search_qa('그러니까 내가 아까 얘기한 부산지검의 명예를 회복하기 위해서 해야 된다는 얘기이고 그 이전의 지검 검사장도 이 지역사회에서 유착되었다는 설도 여기에서는 널리 유포되어 있었습니다. 그런데다가 최근에 두 지검 검사장이 이 사건의 변호인으로 선임되고 하니까 점점 부산지검은 다대ㆍ만덕사건에 관한 한 처음부터 수사를 못 하게 되어 있는 사건이다, 내가 아까 말한 대로 국정감사 때마다 요구하고 추궁하고 또 감사원 감사가 착수되고 하니까 할 수 없이 등 떠밀려서 마지못해서 하는 것 아니냐 하는 것입니다.  수사진은 왜 교체했습니까?')\n",
    "\n",
    "print(f\"question: {results[0][0]}\")\n",
    "print(f\"answer: {results[0][1]}\")\n",
    "print(f\"distance: {results[0][2]}\") # 쿼리 벡터와 찾은 질문 벡터 사이의 거리 (유사도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
